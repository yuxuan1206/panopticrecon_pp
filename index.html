<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PanopticRecon++: Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction">
  <meta name="keywords" content="Autonomous Driving, NeRF, multiple cameras">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PanopticRecon++: Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction</title> 
  <!-- <br>ICML2024 -->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">
  <link rel="stylesheet" type="text/css" href="./static/css/test.css">
  <!-- <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css"> -->
  <link rel="stylesheet" href="./static/css/app.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <link rel="stylesheet" href="./static/css/dics.min.css">
  <script src="./static/js/dics.min.js"></script>

  <style>
    .video-container1 {
      display: flex;
      flex-wrap: wrap;
      justify-content: flex-start;
    }

    .video1 {
      flex: 1 0 22%;
      margin: 8px;
    }
    .divider {
    position: absolute;
    left: 50%;
    top: 0;
    bottom: 0;
    width: 2px;
    background-color: rgb(195, 192, 192);
  }
  .indented {
  margin-top: 2em;
  }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://yuxuan1206.github.io/NFAtlas/">
            NF-Atlas
          </a>
          <a class="navbar-item" href="https://yuxuan1206.github.io/PanopticRecon/">
            PanopticRecon
          </a>
          <a class="navbar-item" href="https://github.com/YunxuanMao/ngel_slam">
            NGEL-SLAM
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction</h1>
          <!-- <h1 class="is-size-4 publication-authors">IROS 2024 (Oral)</h1> -->

          <div class="columns is-centered has-text-centered">
          <!-- <div class="column is-four-fifths"> -->
            <div class="content has-text-justified">
              <img src="./static/images/logo.png"
              width="120">
            </div>
          <!-- </div> -->
        </div>


          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block"> 
             Xuan Yu</a><sup>1</sup>,</span>
              <span class="author-block">
                Yuxuan Xie</a><sup>1</sup>,</span>
              <span class="author-block"> 
                 Yili Liu</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?user=RiX5SJUAAAAJ&hl=zh-CN" target="_blank">Sitong Mao</a><sup>2</sup>,</span>
                      <span class="author-block">
                        <a href="https://scholar.google.com/citations?user=d5qY3q0AAAAJ&hl=en" target="_blank">Shunbo Zhou</a><sup>2</sup>,</span>
                        <span class="author-block">
                          <a href="https://scholar.google.com.hk/citations?user=dNAbVgIAAAAJ&hl=zh-CN" target="_blank">Haojian Lu</a><sup>1</sup>,</span>
                          <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=1hI9bqUAAAAJ&hl=en" target="_blank">Rong Xiong</a><sup>1</sup>,</span>
                                <span class="author-block">
                                  <a href="https://yiyiliao.github.io/" target="_blank">Yiyi Liao</a><sup>1</sup>,</span>
                                      <span class="author-block">
                                        <a href="https://ywang-zju.github.io/" target="_blank">Yue Wang</a><sup>1</sup><sup>*</sup>
                                      </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Zhejiang University,</span>
            <span class="author-block"><sup>2</sup>Huawei,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2501.01119"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.bilibili.com/video/BV1pP61YuEbm/?vd_source=16bffa885f8d40c0678b340384dd56db"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yuxuan1206/PanopticRecon_plus"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser"> -->

<!-- </section> -->

   <!-- <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
    </div>
  </div>  -->

   <!-- Paper video. -->

   <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <!-- <h2 class="title is-3">Method</h2>  -->
      <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
         <source src="./static/videos/teaser.mp4"
                 type="video/mp4">
        </video>
  <!--/ Paper video. -->

  <!-- <div class="image-container">
    <div class="image-overlay"></div>
    <img src="./static/images/zipdemo1.png" alt="Image 1" class="image image1">
    <img src="./static/images/ucdemo1.png" alt="Image 2" class="image image2">
  </div> -->
<!-- </section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- <div id="outer-container">
  <div id="container">
    <img id="image1" src="./static/images/ucdemo1.png" />
    <div id="slider">
      <div class="arrow-right">&#9654;</div>
      <div class="arrow-left">&#9664;</div>
    </div>
    <img id="image2" src="./static/images/zipdemo1.png" />
  </div>
</div>
<script src="./static/js/test.js"></script> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Open-vocabulary panoptic reconstruction offers comprehensive scene understanding, enabling advances in embodied robotics and photorealistic simulation. In this paper, <strong> we propose PanopticRecon++, an end-to-end method that formulates panoptic reconstruction through a novel cross-attention perspective. This perspective models the relationship between 3D instances (as <i> queries </i>) and the scene’s 3D embedding field (as <i>keys</i>) through their attention map.
    Unlike existing methods that separate the optimization of queries and keys or overlook spatial proximity, PanopticRecon++ introduces <i>learnable 3D Gaussians</i> as instance queries. This formulation injects 3D spatial priors to preserve proximity while maintaining end-to-end optimizability. </strong> Moreover, this query formulation facilitates the alignment of 2D open-vocabulary instance IDs across frames by leveraging optimal linear assignment with instance masks rendered from the queries. Additionally, we ensure semantic-instance segmentation consistency by fusing query-based instance segmentation probabilities with semantic probabilities in a novel panoptic head supervised by a panoptic loss.  During training, the number of instance query tokens dynamically adapts to match the number of objects. PanopticRecon++ shows competitive performance in terms of 3D and 2D segmentation and reconstruction performance on both simulation and real-world datasets, and demonstrates a user case as a robot simulator. 
          </p>
          <!-- <p>
          We evaluate PanopticRecon++'s 3D and 2D segmentation and reconstruction performance on simulated and real-world datasets. Experiments demonstrate that PanopticRecon++ outperforms other open-vocabulary methods, particularly in scenes with numerous objects of varying sizes.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <br>

    <!-- Motivation. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <div class="content has-text-justified">
        
          <img src="./static/images/motivation.png">
          <p>
            End-to-end open-vocabulary panoptic reconstruction by 2D foundation model faces three challenges:  
            <p>
              <strong>1) Misalignment:</strong> 2D instance IDs across frames are not align. 
              <br>
              <strong>2) Ambiguity:</strong> Due to the limited FoV, two objects that never co-occur in an image can be the same or different instances. 
              <br>
              <strong>3) Inconsistency:</strong> The semantic and instance segmentations obtained from two independent networks are inconsistent. 
            </p>
            We align 2D instance IDs by instance tokens linear assignment, eliminate the ambiguity of 3D instances by incorporating spatial prior, and output consistent semantic and instance masks by a parameter-free panoptic head, generating the geometric mesh with panoptic masking that allows for multi-branch novel-view synthesis.
          </p>
        </div>
      </div>
    </div>

    <!-- Paper video. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/method.mp4"
                   type="video/mp4">
          </video>
    <!--/ Paper video. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparison</h2> 
        <div class="container">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
           <source src="./static/videos/comparison_outdoor.mp4"
                   type="video/mp4">
          </video>
      </div>
          <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
             <source src="./static/videos/comparison_indoor.mp4"
                     type="video/mp4">
            </video>
        </div> -->
    <!-- / Paper video. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparison</h2>

        <h3 class="title is-4">Panoptic / Semantic Mesh</h3>
        
        <!-- <div class="content has-text-centered"> -->
        <video class="video" width="45%" id="xyalias1" loop playsinline autoplay muted src="./static/videos/mesh-replica-pvlff-compress.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
        <canvas height=0 class="videoMerge" id="xyalias1Merge"></canvas>
        <!-- </div> -->
        <div class="content has-text-justified">
          <p>
            PVLFF has over segmentation and weak semantic segmentation accuracy, while our method can segment object-level instance and demonstrate high accuracy of panoptic/semantic segmentation and reconstruction quality.
          </p>
        </div>

        <!-- <div class="content has-text-centered"> -->
        <video class="video" width="45%" id="xyalias2" loop playsinline autoplay muted src="./static/videos/mesh-replica-PL-compress.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
        <canvas height=0 class="videoMerge" id="xyalias2Merge"></canvas>
        <!-- </div> -->
        <div class="content has-text-justified">
          <p>
            Panoptic Lifting relies only on 2D VLM mask observations without any 3D spatial prior, suffering from FoV limitation, resulting in some tables and chairs in different rooms have the same ID, while our method solves this problem by introducing 3D instance spatial prior.
          </p>
        </div>
        
        <h3 class="title is-4" style="margin-top: +20px">Panoptic / Semantic Rendering</h3>
        <div class="content has-text-justified">
          <p>
            ---
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias9" loop playsinline autoplay muted src="./static/videos/teaser2.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
          <canvas height=0 class="videoMerge" id="xyalias9Merge"></canvas>
        </div> 

        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Robotics Simulator</h2>
          <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/simulator.mp4"
                    type="video/mp4">
            </video>
          </div>
          <div class="content has-text-justified">
            <p>
            Jackal UGV starts navigation in Gazebo with the meshes generated from PanopticRecon++ trained on ScanNet++. 
            </p>
          </div>
        </div>
        

        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered" style="margin-top: +30px">More Results</h2>
        </div>

      </div>
    </div>

  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">More Results</h3>
    </div>

   <p>
    <strong style="color: blue";> 
    Note that no prior used in our GaussianPro.
    </strong>
  </p>
   <section class="hero is-light is-small">
     <div class="hero-body">
       <div class="container">
           <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/scene100613.mp4"
                    type="video/mp4">
           </video>
       </div>
       <div class="container">
        <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/scene148697.mp4"
                  type="video/mp4">
        </video>
    </div>
    <div class="container">
      <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/scene164701.mp4"
                type="video/mp4">
      </video>
      <br>
      <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Images</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Depth</b> &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Rendered Normal</b></p>
      <br>
  </div>
     </div>
   </section>
   <br>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <h3 class="title is-3">Mesh Visualization</h3>
    </div>

   <p>
    <strong style="color: black";> 
      Please note that we did not perform any additional processing on the sky, 
      but it is possible to separate the sky from the foreground by segmenting them as an independent layer during modeling.
    </strong>
  </p>
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/waymo_baseline.mp4" type="video/mp4">
           </video>
         </div>
         <div class="video-container">
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_final.mp4" type="video/mp4">
           </video>
           <video width="320" height="240" autoplay controls muted loop playsinline>
             <source src="./static/videos/room_baseline.mp4" type="video/mp4">
           </video>
         </div>

         <br>
         <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Ours GaussianPro (left)</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>3DGS (right)</b></p>
         <br>

      </div>
    </div>
  </section>
   <br>
</section> -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yu2025leveragecrossattentionendtoendopenvocabulary,
      title={Leverage Cross-Attention for End-to-End Open-Vocabulary Panoptic Reconstruction}, 
      author={Xuan Yu and Yuxuan Xie and Yili Liu and Haojian Lu and Rong Xiong and Yiyi Liao and Yue Wang},
      year={2025},
      eprint={2501.01119},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.01119}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
